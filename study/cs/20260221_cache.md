## 캐시(Cache) 전략의 이해와 효율적인 시스템 설계 방안

시스템의 규모가 커지고 사용자 요청이 급증함에 따라 데이터베이스(DB) 부하를 줄이고 응답 속도를 개선하는 것은 백엔드 개발자의 숙명과도 같습니다. 이러한 성능 최적화의 핵심 도구가 바로 캐시입니다. 캐시를 단순히 데이터를 임시 저장하는 공간으로만 이해하기보다, 서비스의 특성에 맞는 적절한 전략을 선택하여 적용하는 것이 중요합니다. 이번 글에서는 캐시의 기본 개념부터 운영체제 및 애플리케이션 레벨에서의 활용, 그리고 다양한 캐싱 전략의 장단점을 심층적으로 분석합니다.

---

## 캐시의 정의와 필요성

캐시란 데이터나 계산 결과를 미리 저장해 두었다가, 이후 동일한 요청이 올 때 원래의 저장소보다 빠르게 응답을 제공하는 기술을 의미합니다. 수학적 연산인 팩토리얼()을 계산할 때, 이전에 계산한 $(n-1)!$의 값을 캐싱해 두었다면 연산 속도는 비약적으로 향상됩니다. 이는 동적 계획법(Dynamic Programming)의 메모이제이션(Memoization) 원리와도 궤를 같이 합니다.

### 파레토 법칙과 캐싱의 경제성

컴퓨터 공학에서 캐싱이 유효한 이유는 파레토 법칙(80:20 법칙)으로 설명할 수 있습니다. 전체 요청의 80%는 전체 데이터 중 단 20% 내외의 특정 데이터에 집중되는 경향이 있습니다. 따라서 이 빈번하게 조회되는 20%의 데이터를 캐시에 상주시키는 것만으로도 전체 시스템 성능을 극적으로 끌어올릴 수 있습니다.

| 항목 | 설명 | 비고 |
| --- | --- | --- |
| 시간 지역성 | 최근에 접근한 데이터에 다시 접근할 확률이 높음 | For 문 내 변수 등 |
| 공간 지역성 | 접근한 데이터 주변의 데이터에 접근할 확률이 높음 | 배열 순회 등 |
| 캐시 적중(Hit) | 요청한 데이터가 캐시에 존재하는 상태 | 성능 향상 |
| 캐시 미스(Miss) | 캐시에 데이터가 없어 DB 등 원본 저장소에서 조회하는 상태 | 지연 발생 |

---

## 읽기 및 쓰기 전략 분석

캐시를 운영할 때는 데이터의 일관성과 성능 사이의 균형을 맞추기 위해 다양한 읽기(Read) 및 쓰기(Write) 전략을 조합하여 사용합니다.

### 1. 읽기 전략 (Read Strategy)

가장 보편적으로 사용되는 방식은 Look Aside 패턴입니다. 이는 애플리케이션이 캐시를 먼저 확인하고, 데이터가 없을 때만 DB에 접근하는 방식입니다.

* **Look Aside (Cache Aside):** 데이터를 찾을 때 캐시를 우선 확인합니다. 캐시 미스 발생 시 DB에서 조회 후 캐시에 저장합니다. Redis가 다운되더라도 서비스가 완전히 중단되지 않는다는 장점이 있습니다.
* **Read Through:** 애플리케이션이 캐시에서만 데이터를 읽습니다. 데이터가 없으면 캐시 제공자가 DB에서 데이터를 로드하여 캐시를 채운 뒤 반환합니다. 데이터 정합성이 중요한 시스템에 적합합니다.

### 2. 쓰기 전략 (Write Strategy)

데이터를 변경할 때 캐시와 DB 중 어디에 먼저 반영할지에 따라 시스템의 가용성이 결정됩니다.

* **Write Back (Write Behind):** 데이터를 캐시에만 먼저 저장하고, 일정 주기마다 배치 작업을 통해 DB에 반영합니다. 쓰기 쿼리 비용을 크게 줄일 수 있으나, 캐시 장애 시 데이터 유실 위험이 존재합니다.
* **Write Through:** 데이터 저장 시 캐시와 DB에 동시에 기록합니다. 데이터 일관성이 완벽히 보장되지만, 매 요청마다 두 번의 쓰기가 발생하여 성능 저하가 생길 수 있습니다.
* **Write Around:** 모든 데이터는 DB에만 저장하고, 캐시 미스가 발생할 때만 캐시를 갱신합니다. 쓰기 속도는 빠르지만 캐시와 DB 사이의 데이터 불일치가 발생할 수 있습니다.

---

## 스프링 프레임워크에서의 캐시 추상화

스프링 프레임워크는 서비스 로직에 영향을 주지 않고 캐싱을 적용할 수 있도록 강력한 추상화를 제공합니다. 개발자는 AOP(Aspect Oriented Programming) 기반의 애노테이션을 활용하여 비즈니스 로직에만 집중할 수 있습니다.

### Spring Cache Core의 특징

스프링은 기본적으로 Look Aside 패턴을 디폴트로 지원합니다. `@Cacheable` 애노테이션을 메서드에 선언하면, 스프링은 프록시 객체를 통해 캐시 저장소를 먼저 확인합니다. 데이터가 있다면 메서드 본문을 실행하지 않고 결과를 즉시 반환하며, 없다면 메서드를 실행한 후 결과값을 캐시에 저장합니다.

```java
@Service
public class ProductService {

    @Cacheable(value = "products", key = "#id")
    public ProductDto getProductById(Long id) {
        // 캐시에 데이터가 없다면 실제 DB 조회 로직이 실행됩니다.
        return productRepository.findById(id)
            .map(ProductDto::from)
            .orElseThrow();
    }

    @CacheEvict(value = "products", key = "#id")
    public void updateProduct(Long id, ProductUpdateDto dto) {
        // 데이터 수정 시 기존 캐시를 삭제하여 데이터 정합성을 유지합니다.
        Product product = productRepository.findById(id).orElseThrow();
        product.update(dto);
    }
}

```

### 핵심 인터페이스: Cache와 CacheManager

스프링은 저장소 기술에 종속되지 않도록 두 가지 인터페이스를 통해 캐시를 관리합니다.

1. **org.springframework.cache.Cache:** 캐시 데이터의 저장, 조회, 삭제 등 생명주기를 담당합니다.
2. **org.springframework.cache.CacheManager:** 여러 개의 Cache 객체를 관리하는 중앙 제어 역할을 수행합니다. Redis를 사용한다면 `RedisCacheManager`를 구현체로 등록하여 사용합니다.

---

## 결론 및 활용 제안

캐시 전략의 선택은 서비스의 읽기/쓰기 비중과 데이터 정합성의 중요도에 따라 달라져야 합니다. 일반적인 웹 서비스에서는 **Look Aside + Write Around** 조합이 가장 안정적이며 권장되는 방식입니다. 이는 DB 부하를 효과적으로 분산하면서도 캐시 장애 시의 리스크를 최소화할 수 있기 때문입니다.

더 나아가, 캐시 미스 발생 시 대량의 트래픽이 한꺼번에 DB로 몰리는 현상을 방지하기 위해 **Cache Warming**(미리 캐시에 데이터를 로드하는 작업)을 검토해 보시기 바랍니다. 또한, 메모리 자원은 한정적이므로 적절한 TTL(Time To Live) 설정과 만료 정책을 수립하는 것이 시스템 운영의 안정성을 확보하는 지름길입니다.